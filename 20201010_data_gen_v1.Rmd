---
title: "Random Survival Forest Simulator Data Generator"
author: Zach Bohannan
date: Oct 10, 2020
output: html_notebook
---

# Background
## Libraries
```{r}
library(tidyverse)
library(coxed)
library(survival)
library(randomForestSRC)

library(ggRandomForests)

# Akima is simply a supplementary library to support the graphing of tuning data from randomForestSRC
library(akima)
```

## Introduction
### RSF and justification
The random survival forest (RSF) method was recently developed as a powerful machine learning tool for predicting survival, primarily in clinical populations. RSF extends traditional random forests (Breiman) to model cumulative hazard functions for individual patients using an ensemble of decision trees (Ishwaran), with each prediction being informed by the cumulative hazard function of a training population. These models represent a powerful alternative to traditional Cox proportional hazards models and time-to-event analyses.

RSFs have been implemented in several different contexts in both R and python. Both `RandomForestSRC` (https://cran.r-project.org/web/packages/randomForestSRC/citation.html) and `ranger` (https://cran.r-project.org/web/packages/ranger/citation.html) are common R-based implementations of RSF, and python-based RSF has recently been implemented in the `scikit-survival` package (https://scikit-survival.readthedocs.io/en/latest/cite.html). These implementations have been benchmarked on a variety of data as well as being independently supported by third-party research findings.

However, despite intense interest and use, few comprehensive benchmarking studies have been performed on these models. Most third-party benchmarking studies of RSF are focused on a few key aspects of the implementation or data types (for example, https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-017-0383-8). Furthermore, most benchmarking studies are based on a presumption of a particular type or quality level of real-world clinical data, which represents a relatively narrow use case and makes it difficult to fully understand the applicability of RSF methods to common clinical data scenarios such as unbalanced data or small sample sizes. These challenges are exacerbated by the wealth of tuning options for RSF implementations (`RandomForestSRC` calls have 34 listed arguments, and `ranger` calls have 38, although some of those arguments are unlikely to affect predictive performance). The combination of current knowledge gaps and a large number of prospective tuning options makes it nearly impossible to adequately optimize random survival forests for a given real-world use case without detailed background knowledge of model behavior. The goal of this study is to perform RSF benchmarking using simulated gene and survival data.

### Survival data simulation details
Harden (2018) is critical to this endeavor. He describes a relatively elegant solution to simulating survival data that builds the survival and hazard functions in a stepwise manner. First it randomly selects timepoints along the desired duration, and then it randomly selects the same number of values in the [0,1] interval, with 0 and 1 serving as anchor points at time 0 and the max time. These Y values are sorted and then assigned to each chosen timepoint. A cubic spline is constructed along the points using Hyman's method (1983) to ensure montonicity. This represents the cumulative density function (CDF) of the hazard model. The probability density function (PDF) is constructed from the differences between each point . The survival function can be relatively easily constructed by inverting the CDF. Finally, the baseline hazard function is computed by dividing the failure PDF from the survival function (See Fig 1 in Harden).

Covariates are randomly generated (or given by the analyst), and then "true" coefficients are randomly generated as well (these can also be generated by the analyst, which will allow me to set uninformative variables). The combination of covariate and coefficient values represent a linear predictor. This linear predictor is used to calculate exp(XBeta), which represents the percent change from the baseline survival function for a given observation (e.g., 50% lower at all points). Then you randomly select a value from U[0,1] and find the timepoint when the calculated survival function drops below that value. This represents the duration for a given patient. Censoring is calculated independently based on the presumption that censorship mechanisms are not linked to the data generating process (Jackson 2014), which is a reasonable assumption.

## Plan
### Potential data features
#### Variable types
* Binary (e.g., mutation)
  + Roughly 1000 variables, maybe 500 (corresponds with Illumina TruSight 500 panel)
* Ordinal (e.g., severity or stage)
  + 10 (ordinal data are relatively uncommon)
* Unordered factor (e.g., race)
  + 10 UF data are also relatively uncommon
* Continuous percentage (e.g., VAF)
  + Roughly 1000 variables, maybe 500
* Continuous larger numbers with norm distribution (e.g., WBC)
  + 100 variables

#### Percentage of informative variables
* All (100%)
* High (75%)
* Moderate (50%)
* Low (25%)
* Very few (5%)


#### Data balance
* Balanced
* Minor imbalance pos (60/40)
* Minor imbalance neg (40/60)
* Major imbalance pos (75/25)
* Major imbalance neg (25/75)
* Rare events pos (95/5)
* Rare events neg (5/95)

#### Data avail
Log scale values from lots to little
```{r}
exp(seq(log(50), log(1000), length.out = 10))
```
Seems reasonable to use:
50, 70, 97, 136, 189, 264, 368, 514, 717, 1000

### Simulation needs
2000 samples
* Cite Hendry (2014)?; https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.5945
* 1000 samples 0 event
* 1000 samples 1 event
* Can use (https://cran.r-project.org/web/packages/coxed/vignettes/simulating_survival_data.html) to simulate data

Select a random number of each type of sample to equal the percentages given in the above log list. This represents 7 possibilities across 10 data size categories or a matrix of 70 datasets. Then we should select the number of features to be reasonable for a given type of data. 

Start the simulations with homogeneous data types representing "typical" variable numbers:
* Binary
* Continuous percentage
* Continuous log-norm

Each have the 5 levels of informative data
* Randomly filtered
* Uninformative removal

With this list of combinations, I'd be simulating 1050 different data sets. Or rather, I'm combining some smaller amount of simulated data into 1050 different combinations. Still, this seems a little excessive, and initial assessments may lead to a smaller set.


# Methods
## Generic plotting function for randomForestSRC
```{r}
plot.tune <- function(o, linear = TRUE) {
  x <- o$results[,1]
  y <- o$results[,2]
  z <- o$results[,3]
  so <- interp(x=x, y=y, z=z, linear = linear)
  idx <- which.min(z)
  x0 <- x[idx]
  y0 <- y[idx]
  filled.contour(x = so$x,
                 y = so$y,
                 z = so$z,
                 xlim = range(so$x, finite = TRUE) + c(-2, 2),
                 ylim = range(so$y, finite = TRUE) + c(-2, 2),
                 color.palette =colorRampPalette(c("blue", "orange")),
                 xlab = "nodesize",
                 ylab = "mtry",
                 main = "OOB error for nodesize and mtry in tune.rfrsc",
                 key.title = title(main = "OOB error", cex.main = 1),
                 plot.axes = {axis(1); axis(2); points(x0,y0,pch="x",cex=1,font=2); points(x,y,pch=16,cex=.25)})
  }
```
## Initial testing and scoping
To start with the project and learning how to use `coxed`, let's focus on just using binary variables. In this case, the simulation will be:

Simulation Parameter | Value
-------------------- | -----
Sample number        | 2000
Case balance         | Balanced (50/50)
Duration             | 365 days
Variable type        | Normal
Variable number      | 500
Percentage inform    | Norm Dist Coeff

### coxed Tutorial
```{r}
tutorial <- sim.survdata(N=2000, T=365, num.data.frames = 1, censor=0.5, xvars = 500)
head(tutorial$data, 10)
summary(tutorial$data$failed)

ggplot(tutorial$data) + geom_histogram(aes(x=X1)) + ggtitle("Distribution of first sim var")
ggplot() + geom_histogram(aes(x=tutorial$betas)) + ggtitle("Distribution of 'true' coefficients of simulated data")
```

```{r}
tutorial_cox <- coxph(Surv(y, failed) ~ ., data=tutorial$data)
```

These results seem to meet most of our needs. Now we should try it with the types of data we want. We'll generate our own `X`, which is the covariates, and allow the model to randomly assign coefficients. We can do this 5 times as a representative example and plot the various hazard functions.

## Genetic data generation
### Binary data matrix
2000 observations, each with 500 binary variables, representing genetic data taken from a large cancer screen (Illumina TruSight is roughly 500 genes)

Simulation Parameter | Value
-------------------- | -----
Sample number        | 2000
Case balance         | Balanced (50/50)
Duration             | 1825 days (5 years)
Variable type        | Binary
Variable number      | 500
Percentage inform    | Norm Dist (Random)

#### Variable generator function
```{r}
# This function generates a binary data matrix, as might be seen in mutation hotspot data or sequencing panels. var_freq is the integer value of percent positivity in the sample. It can be a single value, in which case the matrix has the same prevalence for every variable, or it can have 2 values, representing the range of possible frequencies. for frequency ranges, the columns are named by their generated freq.
binary_generator <- function(samp_num, var_num, var_freq = 50) {
  if(length(var_freq) == 1){
    message('binary_generator: Fixed frequency mode, fast generation. Pos freq = ',var_freq)
    data_mat <- as.data.frame(matrix(sample(0:1, samp_num * var_num, replace = TRUE, prob = c(1-var_freq/100, var_freq/100)), samp_num, var_num))
  }
  if(length(var_freq) == 2){
    message('binary_generator: Variable frequency mode. Pos freq = ', var_freq[1], ":", var_freq[2])
    freq_matrix <- sample(var_freq[1]:var_freq[2], var_num, replace=TRUE)/100
    for(i in seq_along(freq_matrix)){
      if(i == 1){
        data_mat <- as.data.frame(sample(0:1, samp_num, replace = TRUE, prob = c(1-freq_matrix[i], freq_matrix[i])))
        colnames(data_mat) <- paste0("F",i,"_",freq_matrix[i])
      } else {
        temp <- data.frame(col_tmp = sample(0:1, samp_num, replace = TRUE, prob = c(1-freq_matrix[i], freq_matrix[i])))
        colnames(temp) <- paste0("F",i,"_",freq_matrix[i])
        data_mat <- cbind(data_mat, temp)
      }
    }
  }  
  data_mat
}
```

### Generate initially scoped data matrix
```{r}
set.seed(12345)
gene_panel_input <- binary_generator(samp_num = 2000, var_num = 500)
head(gene_panel_input)
```
### Generate 5 simulated survival datasets
```{r}
sim_genepanel <- sim.survdata(T=1825, num.data.frames = 5, censor=0.5, X=gene_panel_input, knots=37)
```

In this case, the knots are quite variable and definitely affect the distributions of times. If the number of knots is too low, it results in very punctate simulated durations with many durations clustered around a few timepoints. In the case of large time scales (e.g., simulated 5-year survival), T/50 seems to be a reasonable approximation leading to a good variety of data outputs. 

### Diagnostics for simulated data
```{r}
survsim.plot(sim_genepanel, df=1)
survsim.plot(sim_genepanel, df=2)
survsim.plot(sim_genepanel, df=3)
survsim.plot(sim_genepanel, df=4)
survsim.plot(sim_genepanel, df=5)
```

```{r}
coxph(Surv(y, failed) ~ ., data=sim_genepanel[[1]]$data)
head(sim_genepanel[[1]]$betas, 5)
```


## More realistic binary data matrix
This is very similar to before, but the variables have a more realistic distribution in terms of frequency (ranging from 5% to 40% of samples). We're going to cut down the sample sizes a bit too because those were really big models that took way too long previously.

Simulation Parameter | Value
-------------------- | -----
Sample number        | 1000
Case balance         | Balanced (50/50)
Duration             | 1825 days (5 years)
Variable type        | Binary
Variable number      | 300
Percentage inform    | Norm Dist (Random)

```{r}
set.seed(12345)
realistic_panel_input <- binary_generator(samp_num = 1000, var_num = 300, var_freq = c(5,40))
head(realistic_panel_input)
```

### Generate 5 simulated survival datasets
```{r}
sim_realpanel <- sim.survdata(T=1825, num.data.frames = 5, censor=0.5, X=realistic_panel_input, knots=37)
```

### Diagnostics for simulated data
```{r}
survsim.plot(sim_realpanel, df=1)
survsim.plot(sim_realpanel, df=2)
survsim.plot(sim_realpanel, df=3)
survsim.plot(sim_realpanel, df=4)
survsim.plot(sim_realpanel, df=5)
```

```{r}
coxph(Surv(y, failed) ~ ., data=sim_realpanel[[1]]$data)
head(sim_realpanel[[1]]$betas, 5)
```

```{r}
ggplot() + geom_histogram(aes(x=sim_realpanel[[1]]$betas)) + ggtitle("Distribution of 'true' coefficients of simulated real panel")
```

## VAF-style panel data
This is derived wholly from the "realistic" panel data, but it's updated to use VAFs instead of binary data. These VAFs are randomly generated among possible VAFs, with a cap of 1 (germline homozygous variant) and a floor of 0.05, which represents the minimum VAF that can be reliably detected for most variant callers.
```{r}
real_vaf_panel_input <- realistic_panel_input
real_var_panel_input <- apply(real_vaf_panel_input, 1:2, function(x) x*(sample(5:100,1)/100))
```

### Generate 5 simulated survival datasets
```{r}
sim_realVAF_panel <- sim.survdata(T=1825, num.data.frames = 5, censor=0.5, X=real_var_panel_input, knots=37)
```

### Diagnostics for simulated data
```{r}
survsim.plot(sim_realVAF_panel, df=1)
survsim.plot(sim_realVAF_panel, df=2)
survsim.plot(sim_realVAF_panel, df=3)
survsim.plot(sim_realVAF_panel, df=4)
survsim.plot(sim_realVAF_panel, df=5)
```

```{r}
coxph(Surv(y, failed) ~ ., data=sim_realVAF_panel[[1]]$data)
head(sim_realVAF_panel[[1]]$betas, 10)
```

```{r}
ggplot() + geom_histogram(aes(x=sim_realVAF_panel[[1]]$betas)) + ggtitle("Distribution of 'true' coefficients of simulated real panel with VAFs")
```
## Reduced VAF panel data based on selecting only variables with "high" coefficients
These are still quite low in terms of coefficient, so we may need another approach (create smaller lists of variables and then pad them with totally random variables)
```{r}
sim_realVAF_panel_reduc <- list()
```

```{r}
sim_realVAF_panel_reduc[[1]] <- sim_realVAF_panel[[1]]$data[,abs(sim_realVAF_panel[[1]]$betas) > 0.15]
sim_realVAF_panel_reduc[[1]]$y <- sim_realVAF_panel[[1]]$data$y
sim_realVAF_panel_reduc[[1]]$failed <- sim_realVAF_panel[[1]]$data$failed

sim_realVAF_panel_reduc[[2]] <- sim_realVAF_panel[[2]]$data[,abs(sim_realVAF_panel[[2]]$betas) > 0.15]
sim_realVAF_panel_reduc[[2]]$y <- sim_realVAF_panel[[2]]$data$y
sim_realVAF_panel_reduc[[2]]$failed <- sim_realVAF_panel[[2]]$data$failed

sim_realVAF_panel_reduc[[3]] <- sim_realVAF_panel[[3]]$data[,abs(sim_realVAF_panel[[3]]$betas) > 0.15]
sim_realVAF_panel_reduc[[3]]$y <- sim_realVAF_panel[[3]]$data$y
sim_realVAF_panel_reduc[[3]]$failed <- sim_realVAF_panel[[3]]$data$failed

sim_realVAF_panel_reduc[[4]] <- sim_realVAF_panel[[4]]$data[,abs(sim_realVAF_panel[[4]]$betas) > 0.15]
sim_realVAF_panel_reduc[[4]]$y <- sim_realVAF_panel[[4]]$data$y
sim_realVAF_panel_reduc[[4]]$failed <- sim_realVAF_panel[[4]]$data$failed

sim_realVAF_panel_reduc[[5]] <- sim_realVAF_panel[[5]]$data[,abs(sim_realVAF_panel[[5]]$betas) > 0.15]
sim_realVAF_panel_reduc[[5]]$y <- sim_realVAF_panel[[5]]$data$y
sim_realVAF_panel_reduc[[5]]$failed <- sim_realVAF_panel[[5]]$data$failed
```

## Positive control (small number of continuous variables)
Since these seem to behave poorly in the random survival forest, let's take a different approach and build a minimal positive control that we can then modify to test modeling tolerances.

### Generate binary dataset
1000 samples with 20 gene variables should lead to relatively high coefficients.
```{r}
set.seed(12345)
pos_ctrl_input <- binary_generator(samp_num = 1000, var_num = 10, var_freq = c(5,40))
pos_ctrl_input <- apply(pos_ctrl_input, 1:2, function(x) x*(sample(5:100,1)/100))
head(pos_ctrl_input)
```


### Generate 5 simulated survival datasets
```{r}
sim_pos_ctrl <- sim.survdata(T=1825, N=1000, num.data.frames = 5, censor=0.5, knots=37, X=pos_ctrl_input, beta = c(0,-1, 1, -2, 2, -3, 3, -4, 4, 5))
```

### Diagnostics for simulated data
```{r}
survsim.plot(sim_pos_ctrl, df=1)
survsim.plot(sim_pos_ctrl, df=2)
survsim.plot(sim_pos_ctrl, df=3)
survsim.plot(sim_pos_ctrl, df=4)
survsim.plot(sim_pos_ctrl, df=5)
```

```{r}
coxph(Surv(y, failed) ~ ., data=sim_pos_ctrl[[1]]$data)
head(sim_pos_ctrl[[1]]$betas, 10)
```

```{r}
ggplot() + geom_histogram(aes(x=sim_pos_ctrl[[1]]$betas)) + ggtitle("Distribution of 'true' coefficients of simulated VAF positive control")
ggplot() + geom_histogram(aes(x=sim_pos_ctrl[[2]]$betas)) + ggtitle("Distribution of 'true' coefficients of simulated VAF positive control")
ggplot() + geom_histogram(aes(x=sim_pos_ctrl[[3]]$betas)) + ggtitle("Distribution of 'true' coefficients of simulated VAF positive control")
ggplot() + geom_histogram(aes(x=sim_pos_ctrl[[4]]$betas)) + ggtitle("Distribution of 'true' coefficients of simulated VAF positive control")
ggplot() + geom_histogram(aes(x=sim_pos_ctrl[[5]]$betas)) + ggtitle("Distribution of 'true' coefficients of simulated VAF positive control")
```

## Positive control
Let's clean up this positive control a little bit. I think it makes sense to find the "minimum positive control" we can use. 10 variables seems a decent number, but let's see how big the coefficients need to be in order for it to behave well. Maybe we can cut down on the number of aberrant samples at the topend (the warnings thrown by the function).

### Generate data
```{r}
sim_pos_ctrl <- sim.survdata(T=1825, N=1000, num.data.frames = 5, censor=0.5, knots=37, X=pos_ctrl_input, beta = c(0,-0.25, 0.25, -0.5, 0.5, -0.75, 0.75, -1, 1, 2))

```

### Diagnostics for simulated data
```{r}
survsim.plot(sim_pos_ctrl, df=1)
survsim.plot(sim_pos_ctrl, df=2)
survsim.plot(sim_pos_ctrl, df=3)
survsim.plot(sim_pos_ctrl, df=4)
survsim.plot(sim_pos_ctrl, df=5)
```

```{r}
coxph(Surv(y, failed) ~ ., data=sim_pos_ctrl[[1]]$data)
head(sim_pos_ctrl[[1]]$betas, 10)
```

We have an interesting conundrum here. If we generate coefficients less than 1, we are able to reduce the "blowout" that happens as the survival simulator tries to meet the coefficient requirements with zero-inflated data. However, as coefficients decrease below 1, we see highly correlated performance loss in the RSF

## Fixed positive control
The variable positive control seems to work okay but we see an interaction in random survival forest accuracy based on frequency and coefficient. Now what we need to do is generate several datasets with fixed frequency and vary the coefficients, essentially generating a matrix of frequency & coeff variation and then we can track performance. Let's do 10, 20, 40, 60, 80, and 100 percent mutation prevalence.

### Generate binary dataset
Generate 1000 samples with 60 variables ranging in prevalence from 10% to 100%
```{r}
set.seed(12345)
prev_coeff_10 <- binary_generator(samp_num = 1000, var_num = 10, var_freq = 10)
prev_coeff_10 <- apply(prev_coeff_10, 1:2, function(x) x*(sample(5:100,1)/100))

prev_coeff_20 <- binary_generator(samp_num = 1000, var_num = 10, var_freq = 20)
prev_coeff_20 <- apply(prev_coeff_20, 1:2, function(x) x*(sample(5:100,1)/100))

prev_coeff_40 <- binary_generator(samp_num = 1000, var_num = 10, var_freq = 40)
prev_coeff_40 <- apply(prev_coeff_40, 1:2, function(x) x*(sample(5:100,1)/100))

prev_coeff_60 <- binary_generator(samp_num = 1000, var_num = 10, var_freq = 60)
prev_coeff_60 <- apply(prev_coeff_60, 1:2, function(x) x*(sample(5:100,1)/100))

prev_coeff_80 <- binary_generator(samp_num = 1000, var_num = 10, var_freq = 80)
prev_coeff_80 <- apply(prev_coeff_80, 1:2, function(x) x*(sample(5:100,1)/100))

prev_coeff_100 <- binary_generator(samp_num = 1000, var_num = 10, var_freq = 100)
prev_coeff_100 <- apply(prev_coeff_100, 1:2, function(x) x*(sample(5:100,1)/100))
```

```{r}
freq_coeff_mat_input <- cbind(prev_coeff_10, prev_coeff_20, prev_coeff_40, prev_coeff_60, prev_coeff_80, prev_coeff_100)
freq_coeff_mat_input <- as.data.frame(freq_coeff_mat_input)
```

```{r}
colnames(freq_coeff_mat_input) <- c("F10_C0", "F10_Cn.25", "F10_C.25", "F10_Cn.5", "F10_C.5", "F10_Cn.75", "F10_C.75", "F10_Cn1", "F10_C1", "F10_C2","F20_C0", "F20_Cn.25", "F20_C.25", "F20_Cn.5", "F20_C.5", "F20_Cn.75", "F20_C.75", "F20_Cn1", "F20_C1", "F20_C2","F40_C0", "F40_Cn.25", "F40_C.25", "F40_Cn.5", "F40_C.5", "F40_Cn.75", "F40_C.75", "F40_Cn1", "F40_C1", "F40_C2","F60_C0", "F60_Cn.25", "F60_C.25", "F60_Cn.5", "F60_C.5", "F60_Cn.75", "F60_C.75", "F60_Cn1", "F60_C1", "F60_C2","F80_C0", "F80_Cn.25", "F80_C.25", "F80_Cn.5", "F80_C.5", "F80_Cn.75", "F80_C.75", "F80_Cn1", "F80_C1", "F80_C2","F100_C0", "F100_Cn.25", "F100_C.25", "F100_Cn.5", "F100_C.5", "F100_Cn.75", "F100_C.75", "F100_Cn1", "F100_C1", "F100_C2")
```

### Generate survival data
```{r}
freq_coeff_mat <- sim.survdata(T=1825, N=1000, num.data.frames = 5, censor=0.5, knots=37, X=freq_coeff_mat_input, beta = rep(c(0,-0.25, 0.25, -0.5, 0.5, -0.75, 0.75, -1, 1, 2), 6))

```

### Diagnostics for simulated data
```{r}
survsim.plot(freq_coeff_mat, df=1)
survsim.plot(freq_coeff_mat, df=2)
survsim.plot(freq_coeff_mat, df=3)
survsim.plot(freq_coeff_mat, df=4)
survsim.plot(freq_coeff_mat, df=5)
```

Based on the warning, samples 2, 3, and 4 seem to have the best results, but this dataset is exceedingly weird, probably because so much of it is forced into a particular pairing of coefficients with frequency. Even samples 2, 3, and 4 appear highly skewed toward the earlier timepoints. This is not necessarily bad, but we may need to note it for future investigation.

---------------------------------------------

# Results
## Unrealistic genetic data randomForestSRC workflow using default params
### Tuning data
```{r}
tune_genepanel_1 <- tune(Surv(y, failed) ~ ., sim_genepanel[[1]]$data)
tune_genepanel_2 <- tune(Surv(y, failed) ~ ., sim_genepanel[[2]]$data)
tune_genepanel_3 <- tune(Surv(y, failed) ~ ., sim_genepanel[[3]]$data)
tune_genepanel_4 <- tune(Surv(y, failed) ~ ., sim_genepanel[[4]]$data)
tune_genepanel_5 <- tune(Surv(y, failed) ~ ., sim_genepanel[[5]]$data)
```

```{r}
message("Model 1")
plot.tune(tune_genepanel_1)
tune_genepanel_1$optimal
message("Model 2")
plot.tune(tune_genepanel_2)
tune_genepanel_2$optimal
message("Model 3")
plot.tune(tune_genepanel_3)
tune_genepanel_3$optimal
message("Model 4")
plot.tune(tune_genepanel_4)
tune_genepanel_4$optimal
message("Model 5")
plot.tune(tune_genepanel_5)
tune_genepanel_5$optimal

```

### Training data for 50/50 frequency data (unrealistic)
```{r}
rfsrc_genepanel_1 <- rfsrc(Surv(y, failed) ~ ., sim_genepanel[[1]]$data, ntree = 4000, nodesize = 35, mtry=201, importance = TRUE)
rfsrc_genepanel_2 <- rfsrc(Surv(y, failed) ~ ., sim_genepanel[[2]]$data, ntree = 4000, nodesize = 25, mtry=161, importance = TRUE)
rfsrc_genepanel_3 <- rfsrc(Surv(y, failed) ~ ., sim_genepanel[[3]]$data, ntree = 4000, nodesize = 8, mtry=104, importance = TRUE)
rfsrc_genepanel_4 <- rfsrc(Surv(y, failed) ~ ., sim_genepanel[[4]]$data, ntree = 4000, nodesize = 65, mtry=488, importance = TRUE)
rfsrc_genepanel_5 <- rfsrc(Surv(y, failed) ~ ., sim_genepanel[[5]]$data, ntree = 4000, nodesize = 60, mtry=251, importance = TRUE)
```

```{r}
rfsrc_genepanel_1 
rfsrc_genepanel_2 
rfsrc_genepanel_3 
rfsrc_genepanel_4 
rfsrc_genepanel_5 

plot(rfsrc_genepanel_1)
plot(gg_rfsrc(rfsrc_genepanel_1))
plot(rfsrc_genepanel_2)
plot(gg_rfsrc(rfsrc_genepanel_2))
plot(rfsrc_genepanel_3)
plot(gg_rfsrc(rfsrc_genepanel_3))
plot(rfsrc_genepanel_4)
plot(gg_rfsrc(rfsrc_genepanel_4))
plot(rfsrc_genepanel_5)
plot(gg_rfsrc(rfsrc_genepanel_5))
```
These data seem to indicate that for the unrealistic case of balanced binary variables with Cox coefficients normally distributed and maxing out around +/- 0.3, most models will converge by 2000 trees, which will definitely save time simulating as we get deeper into this study. Interestingly, although the coefficients for the variables are normally distributed, variable importance is heavily weighted toward positive importance, and it is not normally distributed.

Now let's try working with a more realistic example. We'll use 500 genes, and they'll have a range of prevalence of mutations from 5% of patients to 40% of patients. This distribution is a little broad to cover most known gene prevalence in cancer, except in cases of cancer with single causative mutations.

## More realistic gene panel results
### Tuning data
```{r}
tune_realpanel_1 <- tune(Surv(y, failed) ~ ., sim_realpanel[[1]]$data)
tune_realpanel_2 <- tune(Surv(y, failed) ~ ., sim_realpanel[[2]]$data)
tune_realpanel_3 <- tune(Surv(y, failed) ~ ., sim_realpanel[[3]]$data)
tune_realpanel_4 <- tune(Surv(y, failed) ~ ., sim_realpanel[[4]]$data)
tune_realpanel_5 <- tune(Surv(y, failed) ~ ., sim_realpanel[[5]]$data)
```

```{r}
message("Model 1")
plot.tune(tune_realpanel_1)
tune_realpanel_1$optimal
message("Model 2")
plot.tune(tune_realpanel_2)
tune_realpanel_2$optimal
message("Model 3")
plot.tune(tune_realpanel_3)
tune_realpanel_3$optimal
message("Model 4")
plot.tune(tune_realpanel_4)
tune_realpanel_4$optimal
message("Model 5")
plot.tune(tune_realpanel_5)
tune_realpanel_5$optimal

```

### Training data for 50/50 frequency data (realistic)
```{r}
rfsrc_realpanel_1 <- rfsrc(Surv(y, failed) ~ ., sim_realpanel[[1]]$data, ntree = 2000, nodesize = 9, mtry=300, importance = TRUE)
rfsrc_realpanel_2 <- rfsrc(Surv(y, failed) ~ ., sim_realpanel[[2]]$data, ntree = 2000, nodesize = 55, mtry=293, importance = TRUE)
rfsrc_realpanel_3 <- rfsrc(Surv(y, failed) ~ ., sim_realpanel[[3]]$data, ntree = 2000, nodesize = 7, mtry=188, importance = TRUE)
rfsrc_realpanel_4 <- rfsrc(Surv(y, failed) ~ ., sim_realpanel[[4]]$data, ntree = 2000, nodesize = 25, mtry=63, importance = TRUE)
rfsrc_realpanel_5 <- rfsrc(Surv(y, failed) ~ ., sim_realpanel[[5]]$data, ntree = 2000, nodesize = 25, mtry=151, importance = TRUE)
```

```{r}
rfsrc_realpanel_1 
rfsrc_realpanel_2 
rfsrc_realpanel_3 
rfsrc_realpanel_4 
rfsrc_realpanel_5 

plot(rfsrc_realpanel_1)
plot(gg_rfsrc(rfsrc_realpanel_1))
plot(rfsrc_realpanel_2)
plot(gg_rfsrc(rfsrc_realpanel_2))
plot(rfsrc_realpanel_3)
plot(gg_rfsrc(rfsrc_realpanel_3))
plot(rfsrc_realpanel_4)
plot(gg_rfsrc(rfsrc_realpanel_4))
plot(rfsrc_realpanel_5)
plot(gg_rfsrc(rfsrc_realpanel_5))
```

Interesting. So that still doesn't work worth a hoot for binary data. Now we have two ways to go: we can try the same type of pipeline but for smaller numbers of genes, or we can try changing to VAF and seeing how the continuous data preferences of random forests translate to RSF. Let's try using the same matrix but converting the "1" values to continuous values between 0.1 and 1.

## Realistic gene sequencing panel data using VAFs, with the previous matrix converted to VAF
I am somewhat concerned here that the coefficients from the continuous variables are not high enough (mostly < abs(0.2)), but we will see if the models can derive anything useful from them. We may have to manually set the coefficients for these data. But first let's do a baseline, then we can work on setting fixed coefficients and seeing if filtering low coefficients from Cox PH can help.

### Tuning data
```{r}
tune_VAFpanel_1 <- tune(Surv(y, failed) ~ ., sim_realVAF_panel[[1]]$data)
tune_VAFpanel_2 <- tune(Surv(y, failed) ~ ., sim_realVAF_panel[[2]]$data)
tune_VAFpanel_3 <- tune(Surv(y, failed) ~ ., sim_realVAF_panel[[3]]$data)
tune_VAFpanel_4 <- tune(Surv(y, failed) ~ ., sim_realVAF_panel[[4]]$data)
tune_VAFpanel_5 <- tune(Surv(y, failed) ~ ., sim_realVAF_panel[[5]]$data)
```

```{r}
message("Model 1")
plot.tune(tune_VAFpanel_1)
tune_VAFpanel_1$optimal
message("Model 2")
plot.tune(tune_VAFpanel_2)
tune_VAFpanel_2$optimal
message("Model 3")
plot.tune(tune_VAFpanel_3)
tune_VAFpanel_3$optimal
message("Model 4")
plot.tune(tune_VAFpanel_4)
tune_VAFpanel_4$optimal
message("Model 5")
plot.tune(tune_VAFpanel_5)
tune_VAFpanel_5$optimal

```

### Training using VAF data derived from same binary data
```{r}
rfsrc_VAFpanel_1 <- rfsrc(Surv(y, failed) ~ ., sim_realVAF_panel[[1]]$data, ntree = 2000, nodesize = 30, mtry=51, importance = TRUE)
rfsrc_VAFpanel_2 <- rfsrc(Surv(y, failed) ~ ., sim_realVAF_panel[[2]]$data, ntree = 2000, nodesize = 75, mtry=51, importance = TRUE)
rfsrc_VAFpanel_3 <- rfsrc(Surv(y, failed) ~ ., sim_realVAF_panel[[3]]$data, ntree = 2000, nodesize = 25, mtry=33, importance = TRUE)
rfsrc_VAFpanel_4 <- rfsrc(Surv(y, failed) ~ ., sim_realVAF_panel[[4]]$data, ntree = 2000, nodesize = 35, mtry=63, importance = TRUE)
rfsrc_VAFpanel_5 <- rfsrc(Surv(y, failed) ~ ., sim_realVAF_panel[[5]]$data, ntree = 2000, nodesize = 50, mtry=51, importance = TRUE)
```

```{r}
rfsrc_VAFpanel_1 
rfsrc_VAFpanel_2 
rfsrc_VAFpanel_3 
rfsrc_VAFpanel_4 
rfsrc_VAFpanel_5 

plot(rfsrc_VAFpanel_1)
plot(gg_rfsrc(rfsrc_VAFpanel_1))
plot(rfsrc_VAFpanel_2)
plot(gg_rfsrc(rfsrc_VAFpanel_2))
plot(rfsrc_VAFpanel_3)
plot(gg_rfsrc(rfsrc_VAFpanel_3))
plot(rfsrc_VAFpanel_4)
plot(gg_rfsrc(rfsrc_VAFpanel_4))
plot(rfsrc_VAFpanel_5)
plot(gg_rfsrc(rfsrc_VAFpanel_5))
```

## Realistic gene sequencing panel data using VAFs, selected down based on coefficient
The performance for the previous models was relatively abysmal (rarely above 0.45% accuracy despite Cox capturing nearly all of the variability). Let's see if we can get better performance by forcibly reducing the data down to only the highest coefficients. Since most coefficients are below abs(1.5), let's try that first.

### Tuning data
```{r}
tune_VAFpanel_reduc_1 <- tune(Surv(y, failed) ~ ., as.data.frame(sim_realVAF_panel_reduc[[1]]))
tune_VAFpanel_reduc_2 <- tune(Surv(y, failed) ~ ., as.data.frame(sim_realVAF_panel_reduc[[2]]))
tune_VAFpanel_reduc_3 <- tune(Surv(y, failed) ~ ., as.data.frame(sim_realVAF_panel_reduc[[3]]))
tune_VAFpanel_reduc_4 <- tune(Surv(y, failed) ~ ., as.data.frame(sim_realVAF_panel_reduc[[4]]))
tune_VAFpanel_reduc_5 <- tune(Surv(y, failed) ~ ., as.data.frame(sim_realVAF_panel_reduc[[5]]))
```

```{r}
message("Model 1")
plot.tune(tune_VAFpanel_reduc_1)
tune_VAFpanel_reduc_1$optimal
message("Model 2")
plot.tune(tune_VAFpanel_reduc_2)
tune_VAFpanel_reduc_2$optimal
message("Model 3")
plot.tune(tune_VAFpanel_reduc_3)
tune_VAFpanel_reduc_3$optimal
message("Model 4")
plot.tune(tune_VAFpanel_reduc_4)
tune_VAFpanel_reduc_4$optimal
message("Model 5")
plot.tune(tune_VAFpanel_reduc_5)
tune_VAFpanel_reduc_5$optimal

```

### Training using VAF data derived from same binary data
```{r}
rfsrc_VAFpanel_reduc_1 <- rfsrc(Surv(y, failed) ~ ., sim_realVAF_panel_reduc[[1]], ntree = 2000, nodesize = 8, mtry=7, importance = TRUE)
rfsrc_VAFpanel_reduc_2 <- rfsrc(Surv(y, failed) ~ ., sim_realVAF_panel_reduc[[2]], ntree = 2000, nodesize = 50, mtry=8, importance = TRUE)
rfsrc_VAFpanel_reduc_3 <- rfsrc(Surv(y, failed) ~ ., sim_realVAF_panel_reduc[[3]], ntree = 2000, nodesize = 75, mtry=7, importance = TRUE)
rfsrc_VAFpanel_reduc_4 <- rfsrc(Surv(y, failed) ~ ., sim_realVAF_panel_reduc[[4]], ntree = 2000, nodesize = 35, mtry=8, importance = TRUE)
rfsrc_VAFpanel_reduc_5 <- rfsrc(Surv(y, failed) ~ ., sim_realVAF_panel_reduc[[5]], ntree = 2000, nodesize = 20, mtry=9, importance = TRUE)
```

```{r}
rfsrc_VAFpanel_reduc_1 
rfsrc_VAFpanel_reduc_2 
rfsrc_VAFpanel_reduc_3 
rfsrc_VAFpanel_reduc_4 
rfsrc_VAFpanel_reduc_5 

plot(rfsrc_VAFpanel_reduc_1)
plot(gg_rfsrc(rfsrc_VAFpanel_reduc_1))
plot(rfsrc_VAFpanel_reduc_2)
plot(gg_rfsrc(rfsrc_VAFpanel_reduc_2))
plot(rfsrc_VAFpanel_reduc_3)
plot(gg_rfsrc(rfsrc_VAFpanel_reduc_3))
plot(rfsrc_VAFpanel_reduc_4)
plot(gg_rfsrc(rfsrc_VAFpanel_reduc_4))
plot(rfsrc_VAFpanel_reduc_5)
plot(gg_rfsrc(rfsrc_VAFpanel_reduc_5))
```

Interestingly, it seems like even if we select down to just the highest absolute values of coefficients (roughly 50 vars per model), it's still not enough at these coefficient levels. We may need much higher HRs among variables to detect them successfully. This was a rather naive approach in retrospect. A better approach will probably be to find a positive control and then fiddle "upward" until I find the tolerances of the random survival forest.

## Positive control models
We'll try generating positive controls that mimic real-world genetic data using VAFs and see if we can actually decently model them with a minimum number of variables. One would expect that 20 random variables would be sufficient to generate good coefficients, but many of these coefficients seem relatively low. We'll see what we can do with this, but I remain less than hopeful.

### Tuning data
```{r}
tune_posctrl_1 <- tune(Surv(y, failed) ~ ., sim_pos_ctrl[[1]]$data)
tune_posctrl_2 <- tune(Surv(y, failed) ~ ., sim_pos_ctrl[[2]]$data)
tune_posctrl_3 <- tune(Surv(y, failed) ~ ., sim_pos_ctrl[[3]]$data)
tune_posctrl_4 <- tune(Surv(y, failed) ~ ., sim_pos_ctrl[[4]]$data)
tune_posctrl_5 <- tune(Surv(y, failed) ~ ., sim_pos_ctrl[[5]]$data)
```

```{r}
message("Model 1")
plot.tune(tune_posctrl_1)
tune_posctrl_1$optimal
message("Model 2")
plot.tune(tune_posctrl_2)
tune_posctrl_2$optimal
message("Model 3")
plot.tune(tune_posctrl_3)
tune_posctrl_3$optimal
message("Model 4")
plot.tune(tune_posctrl_4)
tune_posctrl_4$optimal
message("Model 5")
plot.tune(tune_posctrl_5)
tune_posctrl_5$optimal

```

### Training using VAF data derived from same binary data
```{r}
rfsrc_posctrl_1 <- rfsrc(Surv(y, failed) ~ ., sim_pos_ctrl[[1]]$data, ntree = 2000, nodesize = 60, mtry=2, importance = TRUE)
rfsrc_posctrl_2 <- rfsrc(Surv(y, failed) ~ ., sim_pos_ctrl[[2]]$data, ntree = 2000, nodesize = 70, mtry=4, importance = TRUE)
rfsrc_posctrl_3 <- rfsrc(Surv(y, failed) ~ ., sim_pos_ctrl[[3]]$data, ntree = 2000, nodesize = 40, mtry=3, importance = TRUE)
rfsrc_posctrl_4 <- rfsrc(Surv(y, failed) ~ ., sim_pos_ctrl[[4]]$data, ntree = 2000, nodesize = 75, mtry=1, importance = TRUE)
rfsrc_posctrl_5 <- rfsrc(Surv(y, failed) ~ ., sim_pos_ctrl[[5]]$data, ntree = 2000, nodesize = 55, mtry=2, importance = TRUE)
```

```{r}
rfsrc_posctrl_1 
rfsrc_posctrl_2 
rfsrc_posctrl_3 
rfsrc_posctrl_4 
rfsrc_posctrl_5 

plot(rfsrc_posctrl_1)
plot(gg_rfsrc(rfsrc_posctrl_1))
plot(rfsrc_posctrl_2)
plot(gg_rfsrc(rfsrc_posctrl_2))
plot(rfsrc_posctrl_3)
plot(gg_rfsrc(rfsrc_posctrl_3))
plot(rfsrc_posctrl_4)
plot(gg_rfsrc(rfsrc_posctrl_4))
plot(rfsrc_posctrl_5)
plot(gg_rfsrc(rfsrc_posctrl_5))
```

Well, this appears promising, but it is also appears to show that the plots for 1000 patients seems to be a bit misleading because the resolution is simply too low. Given the accuracy of the model, it appears that the lower events may represent patients who experience relapse late in their disease course. In any case, let's try it with something more approximating genetic data.

It seems the source of the problems may be the zero-inflation of genetic data. But we need a way to get around that if possible. The sparsity means rather low coefficients for survival in most cases.

If we reduce the coefficients to minimize the "blowout", we also see a directly correlated loss in OOB performance. Interestingly, most of the RSF models seem to favor higher coefficients in importance, but there appears to be some interaction between prevalence and coefficient. Even though F10 has the highest coefficient in this model, it also has the lowest prevalence, and F6-9 have lower coefficients but higher prevalence and are often ranked higher in variable importance. However, this could also be the effect of the zero-inflation.

## Freq x coeff models
We'll try generating positive controls that mimic real-world genetic data using VAFs and see if we can actually decently model them with a minimum number of variables. One would expect that 20 random variables would be sufficient to generate good coefficients, but many of these coefficients seem relatively low. We'll see what we can do with this, but I remain less than hopeful.


### Tuning data
```{r}
tune_fvc_1 <- tune(Surv(y, failed) ~ ., freq_coeff_mat[[1]]$data)
tune_fvc_2 <- tune(Surv(y, failed) ~ ., freq_coeff_mat[[2]]$data)
tune_fvc_3 <- tune(Surv(y, failed) ~ ., freq_coeff_mat[[3]]$data)
tune_fvc_4 <- tune(Surv(y, failed) ~ ., freq_coeff_mat[[4]]$data)
tune_fvc_5 <- tune(Surv(y, failed) ~ ., freq_coeff_mat[[5]]$data)
```

```{r}
message("Model 1")
plot.tune(tune_fvc_1)
tune_fvc_1$optimal
message("Model 2")
plot.tune(tune_fvc_2)
tune_fvc_2$optimal
message("Model 3")
plot.tune(tune_fvc_3)
tune_fvc_3$optimal
message("Model 4")
plot.tune(tune_fvc_4)
tune_fvc_4$optimal
message("Model 5")
plot.tune(tune_fvc_5)
tune_fvc_5$optimal
```

### Training using VAF data derived from same binary data
```{r}
rfsrc_fvc_1 <- rfsrc(Surv(y, failed) ~ ., freq_coeff_mat[[1]]$data, ntree = 2000, nodesize = 15, mtry=11, importance = TRUE)
rfsrc_fvc_2 <- rfsrc(Surv(y, failed) ~ ., freq_coeff_mat[[2]]$data, ntree = 2000, nodesize = 45, mtry=13, importance = TRUE)
rfsrc_fvc_3 <- rfsrc(Surv(y, failed) ~ ., freq_coeff_mat[[3]]$data, ntree = 2000, nodesize = 25, mtry=11, importance = TRUE)
rfsrc_fvc_4 <- rfsrc(Surv(y, failed) ~ ., freq_coeff_mat[[4]]$data, ntree = 2000, nodesize = 40, mtry=11, importance = TRUE)
rfsrc_fvc_5 <- rfsrc(Surv(y, failed) ~ ., freq_coeff_mat[[5]]$data, ntree = 2000, nodesize = 15, mtry=20, importance = TRUE)
```

```{r}
rfsrc_fvc_1 
rfsrc_fvc_2 
rfsrc_fvc_3 
rfsrc_fvc_4 
rfsrc_fvc_5 

plot(rfsrc_fvc_1)
plot(gg_rfsrc(rfsrc_fvc_1))
plot(rfsrc_fvc_2)
plot(gg_rfsrc(rfsrc_fvc_2))
plot(rfsrc_fvc_3)
plot(gg_rfsrc(rfsrc_fvc_3))
plot(rfsrc_fvc_4)
plot(gg_rfsrc(rfsrc_fvc_4))
plot(rfsrc_fvc_5)
plot(gg_rfsrc(rfsrc_fvc_5))
```
Variable importance calculations
```{r}
var_imp_test <- data.frame(varname=names(rfsrc_fvc_3[["importance"]]), importance = rfsrc_fvc_3[["importance"]])

var_imp_test %>% ggplot() + geom_bar(aes(x=reorder(varname, -importance), y=importance), stat="identity") + theme(axis.text.x = element_text(angle=90, hjust=1, vjust=0.5)) + labs(title="Variable Importance", x="Variables", y="Variable Importance - Permutation change in OOB")
```

Setup code to generate colorized heatmap of frequency versus coefficient
```{r}
fvc1 <- data.frame(varname=names(rfsrc_fvc_1[["importance"]]), importance = rfsrc_fvc_1[["importance"]])
fvc1$freq <- c(rep(10,10), rep(20,10), rep(40,10), rep(60,10), rep(80,10), rep(100,10))
fvc1$coeff <- rep(c(0,-0.25, 0.25, -0.5, 0.5, -0.75, 0.75, -1, 1, 2), 6)

fvc2 <- data.frame(varname=names(rfsrc_fvc_2[["importance"]]), importance = rfsrc_fvc_2[["importance"]])
fvc2$freq <- c(rep(10,10), rep(20,10), rep(40,10), rep(60,10), rep(80,10), rep(100,10))
fvc2$coeff <- rep(c(0,-0.25, 0.25, -0.5, 0.5, -0.75, 0.75, -1, 1, 2), 6)

fvc3 <- data.frame(varname=names(rfsrc_fvc_3[["importance"]]), importance = rfsrc_fvc_3[["importance"]])
fvc3$freq <- c(rep(10,10), rep(20,10), rep(40,10), rep(60,10), rep(80,10), rep(100,10))
fvc3$coeff <- rep(c(0,-0.25, 0.25, -0.5, 0.5, -0.75, 0.75, -1, 1, 2), 6)

fvc4 <- data.frame(varname=names(rfsrc_fvc_4[["importance"]]), importance = rfsrc_fvc_4[["importance"]])
fvc4$freq <- c(rep(10,10), rep(20,10), rep(40,10), rep(60,10), rep(80,10), rep(100,10))
fvc4$coeff <- rep(c(0,-0.25, 0.25, -0.5, 0.5, -0.75, 0.75, -1, 1, 2), 6)

fvc5 <- data.frame(varname=names(rfsrc_fvc_5[["importance"]]), importance = rfsrc_fvc_5[["importance"]])
fvc5$freq <- c(rep(10,10), rep(20,10), rep(40,10), rep(60,10), rep(80,10), rep(100,10))
fvc5$coeff <- rep(c(0,-0.25, 0.25, -0.5, 0.5, -0.75, 0.75, -1, 1, 2), 6)
```

```{r}
ggplot(fvc1) + geom_contour_filled(aes(x=freq, y=coeff, z=importance)) + ggtitle("Simulation 1") + labs(fill="Variable importance")
ggplot(fvc1) + geom_tile(aes(x=freq, y=coeff, fill=importance)) + scale_fill_gradient(low="yellow",high="blue") + ggtitle("Simulation 1")

ggplot(fvc2) + geom_contour_filled(aes(x=freq, y=coeff, z=importance))+ ggtitle("Simulation 2") + labs(fill="Variable importance")
ggplot(fvc2) + geom_tile(aes(x=freq, y=coeff, fill=importance)) + scale_fill_gradient(low="yellow",high="blue") + ggtitle("Simulation 2")

ggplot(fvc3) + geom_contour_filled(aes(x=freq, y=coeff, z=importance)) + ggtitle("Simulation 3") + labs(fill="Variable importance")
ggplot(fvc3) + geom_tile(aes(x=freq, y=coeff, fill=importance)) + scale_fill_gradient(low="yellow",high="blue") + ggtitle("Simulation 3")

ggplot(fvc4) + geom_contour_filled(aes(x=freq, y=coeff, z=importance)) + ggtitle("Simulation 4") + labs(fill="Variable importance")
ggplot(fvc4) + geom_tile(aes(x=freq, y=coeff, fill=importance)) + scale_fill_gradient(low="yellow",high="blue") + ggtitle("Simulation 4")

ggplot(fvc5) + geom_contour_filled(aes(x=freq, y=coeff, z=importance)) + ggtitle("Simulation 5") + labs(fill="Variable importance")
ggplot(fvc5) + geom_tile(aes(x=freq, y=coeff, fill=importance)) + scale_fill_gradient(low="yellow",high="blue") + ggtitle("Simulation 5")
```

## Investigate criteria for variable selection
There are some outstanding questions how frequency interacts with the Wald p-value and other calculations. Specifically, we would like to understand how frequency affects the coefficient and its p-value in univariate Cox maximum likelihood estimates.

We can better understand this by calculating the univariate Cox PH per variable per model and see if there are any important trends.

This code is modified from http://www.sthda.com/english/wiki/cox-proportional-hazards-model#compute-the-cox-model

```{r}
covariates <- colnames(freq_coeff_mat[[1]]$data[,1:60])
univ_formulas <- sapply(covariates,
                        function(x) as.formula(paste('Surv(y, failed)~', x)))
```

```{r}
fc1_cox_models <- lapply( univ_formulas, function(x){coxph(x, data = freq_coeff_mat[[1]]$data)})
# Extract data 
fc1_cox_results <- lapply(fc1_cox_models,
                       function(x){ 
                          x <- summary(x)
                          p.value<-signif(x$wald["pvalue"], digits=2)
                          wald.test<-signif(x$wald["test"], digits=2)
                          beta<-signif(x$coef[1], digits=2);#coeficient beta
                          HR <-signif(x$coef[2], digits=2);#exp(beta)
                          HR.confint.lower <- signif(x$conf.int[,"lower .95"], 2)
                          HR.confint.upper <- signif(x$conf.int[,"upper .95"],2)
                          HR <- paste0(HR, " (", 
                                       HR.confint.lower, "-", HR.confint.upper, ")")
                          res<-c(beta, HR, wald.test, p.value)
                          names(res)<-c("beta", "HR (95% CI for HR)", "wald.test", 
                                        "p.value")
                          return(res)
                          #return(exp(cbind(coef(x),confint(x))))
                         })
fc1_cox_results <- t(as.data.frame(fc1_cox_results, check.names = FALSE))
fc1_cox_results <- as.data.frame(fc1_cox_results)
```
```{r}
fc1_cox_results$freq <- c(rep(10,10), rep(20,10), rep(40,10), rep(60,10), rep(80,10), rep(100,10))
fc1_cox_results$coeff <- rep(c(0,-0.25, 0.25, -0.5, 0.5, -0.75, 0.75, -1, 1, 2), 6)
```

```{r}
ggplot(fc1_cox_results) + geom_text(aes(x=as.numeric(as.character(beta)), y=as.numeric(as.character(p.value)), label=rownames(fc1_cox_results)))

ggplot(fc1_cox_results) + geom_contour_filled(aes(x=freq, y=coeff, z=as.numeric(as.character(beta)))) + ggtitle("Simulation 1") + labs(fill="Cox Coeff")

ggplot(fc1_cox_results) + geom_tile(aes(x=freq, y=coeff, fill=as.numeric(as.character(beta)))) + scale_fill_gradient(low="yellow",high="blue") + ggtitle("Cox Coeff")
```

```{r}
ggplot(fc1_cox_results) + geom_contour_filled(aes(x=freq, y=coeff, z=as.numeric(as.character(p.value)))) + ggtitle("Simulation 1") + labs(fill="Wald P-value")

ggplot(fc1_cox_results) + geom_tile(aes(x=freq, y=coeff, fill=as.numeric(as.character(p.value)))) + scale_fill_gradient(low="blue",high="yellow") + ggtitle("Wald P-value")
```

# Conclusions
Random survival forests appear to show some variability in terms of effectively selecting simulated "genomic-like" data when variables are simulated to represent VAF scores. In variables with univariable Cox proportional hazards lower than 1, random survival forests are unable to effectively identify important variables.

Furthermore, zero inflation appears to be important for random survival forest performance. Genes that have simulated "mutational frequency" less than 20% appear to be less reliable than more frequently mutated genes.

Both of these results are almost certainly related to the splitting process in individual trees of the random survival forest. Most likely, the effects of rare and/or low-coefficient genes are so small that most of the weak predictors in the random survival forest ensemble are unable to effectively split the data.
